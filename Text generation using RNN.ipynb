{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation using RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IBK27uyOsSU"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIe0BURpTYSW",
        "outputId": "d8341a07-b568-4085-cb66-6926f9a73953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt',\n",
        "                                     'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4qxT9DaTm5n",
        "outputId": "d15e04ce-9fde-48c2-91ff-56703a7b4ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "path_to_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/shakespeare.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGZNkH_T0eS",
        "outputId": "2aacfd58-a977-40e3-8d2a-df743cff1b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Experiment and see the difference\n",
        "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print(f'Length of text:{len(text)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text:1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv3ctdhGUK0V",
        "outputId": "4a152f9e-0d56-4fd2-ba94-0d54cd3c5505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(text[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCd535eBUg87",
        "outputId": "2ac4cb1e-e0d5-4b29-c548-46a77a23e003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab=sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzjtI3CpV6KD"
      },
      "source": [
        "Process the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOVcV_4lVqis"
      },
      "source": [
        "#text is string\n",
        "char2idx={u:i for i,u in enumerate(vocab)}\n",
        "idx2char=np.array(vocab)\n",
        "\n",
        "text_as_int=np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x508ctuWU8z",
        "outputId": "c21db87f-572b-4cce-ef8d-b307fc6c4c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text_as_int.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115394,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg7-vRzpW5vc",
        "outputId": "c6573a1b-baf0-430a-fbba-0f19c40f9e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "char2idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1hPTJddXKhl",
        "outputId": "c958740c-847f-47e6-c92f-1a132f2c7d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('{}---characters mapped to int---->{}'.format(text[:13],text_as_int[:13]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen---characters mapped to int---->[18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSSjicXAXi5E"
      },
      "source": [
        "seq_length=100\n",
        "examples_per_epoch=len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jMlNjWcrX-m",
        "outputId": "d7655f79-3000-43e7-eeb4-3a63220ec37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDEGsbpksbur",
        "outputId": "81f738a0-c382-4fde-a505-e1add02b4cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#repr->printable representation of an object(\\n is displayed and not a next line)\n",
        "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(2):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auLNnGXNtMCA",
        "outputId": "c4876b27-27ad-422e-d37d-9f51d8bd4d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (101,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWfM5YsStslN"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text=chunk[:-1]\n",
        "  target_text=chunk[1:]\n",
        "  return input_text,target_text\n",
        "\n",
        "dataset=sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22OyuCOhumZa",
        "outputId": "eb8e2da2-8122-4659-8d57-c030de628105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su4l0GVMvIF7",
        "outputId": "4ba5156c-9cda-4f31-a976-57c031f2178d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              " array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
              "        44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39,\n",
              "        52, 63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1,\n",
              "        51, 43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31,\n",
              "        54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56,\n",
              "        57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59])>,\n",
              " <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              " array([47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52,\n",
              "        63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51,\n",
              "        43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54,\n",
              "        43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57,\n",
              "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxHyHGNwO5X",
        "outputId": "0339c0af-04d5-4b97-c5ff-f8ebf7ce87aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "for i,(input_idx,target_idx) in enumerate(zip(input_example[:5],target_example[:5])):\n",
        "  print('Step:{}'.format(i))\n",
        "  print('Input:{}({})'.format(input_idx,repr(idx2char[input_idx])))\n",
        "  print('Expected output:{}({})'.format(target_idx,repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:0\n",
            "Input:18('F')\n",
            "Expected output:47('i')\n",
            "Step:1\n",
            "Input:47('i')\n",
            "Expected output:56('r')\n",
            "Step:2\n",
            "Input:56('r')\n",
            "Expected output:57('s')\n",
            "Step:3\n",
            "Input:57('s')\n",
            "Expected output:58('t')\n",
            "Step:4\n",
            "Input:58('t')\n",
            "Expected output:1(' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYDX6457x4aa",
        "outputId": "b7eadfd4-aaca-43d8-ebcf-6e279872054b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "BATCH_SIZE=64\n",
        "BUFFER_SIZE=10000\n",
        "dataset=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdzYduShyIoH"
      },
      "source": [
        "vocab_size=len(vocab)\n",
        "embedding_dim=256\n",
        "rnn_units=1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBujN2SFykhg"
      },
      "source": [
        "model=tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,embedding_dim,\n",
        "                                batch_input_shape=(BATCH_SIZE,None)),\n",
        "      tf.keras.layers.GRU(rnn_units,return_sequences=True,stateful=True,\n",
        "                          recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjHZeL200X83",
        "outputId": "930c632b-b814-41d9-86c1-828d92ed6e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for input_example_batch,target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions=model(input_example_batch)\n",
        "  print(example_batch_predictions.shape)   #batch_size, sequence_length, vocab_size) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ADQm8C1-wV",
        "outputId": "21ba4054-bf5f-47d8-d362-6183aea470e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "target_tokens=tf.argmax(example_batch_predictions,axis=-1)\n",
        "target_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
              "array([[33, 54, 54, ..., 62, 61, 27],\n",
              "       [27, 29, 11, ..., 50, 50, 46],\n",
              "       [62,  9, 29, ..., 54, 43, 46],\n",
              "       ...,\n",
              "       [ 6, 55, 50, ..., 43, 54, 29],\n",
              "       [35, 54, 14, ..., 25,  3, 21],\n",
              "       [29, 50, 24, ..., 23, 12, 54]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7GwPyHo2QCC",
        "outputId": "ff3a8e30-2682-45cb-dfbe-e671d7a1ac4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "target_char=[idx2char[i] for i in target_tokens[0].numpy()]\n",
        "print(''.join(target_char))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UppP$pUpeLQQlp.$.$!PLDp!H;;;KpP,lll$$eb.L!!x..Q...!ll$k??-$pQkQPLDp::FkAQLkL$b!DwJ::XUH-K-lXHpBCPxwO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px-IyfMy06m9",
        "outputId": "b4da9713-d00f-4b8e-a1da-89aa38debeaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm7Hypmd5VPe",
        "outputId": "aaf54d6b-cd87-4601-b6ac-a2614ac77a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)\n",
        "\n",
        "example_batch_loss=loss(target_example_batch,example_batch_predictions)\n",
        "print(\"Prediction shape:\", example_batch_predictions.shape)\n",
        "print(\"scalar_loss:\", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape: (64, 100, 65)\n",
            "scalar_loss: 4.1750875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RelROfWk8Dpa"
      },
      "source": [
        "model.compile(optimizer='adam',loss=loss,metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJY8uJSK9W1N"
      },
      "source": [
        "#Directory where the checkpoints will be saved\n",
        "checkpoint_dir='./training_checkpoints'\n",
        "#Name of the checkpoint files\n",
        "checkpoint_prefix=os.path.join(checkpoint_dir,'ckpt_{epoch}')\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mea_KmIu-P3O",
        "outputId": "98c954a6-d97a-4e23-8a55-234fb8f69557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "history=model.fit(dataset,epochs=10,callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 21s 124ms/step - loss: 2.6452 - acc: 0.2878\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 21s 125ms/step - loss: 1.9520 - acc: 0.4298\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 22s 126ms/step - loss: 1.6865 - acc: 0.5014\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 22s 127ms/step - loss: 1.5416 - acc: 0.5401\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 22s 128ms/step - loss: 1.4541 - acc: 0.5626\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 22s 128ms/step - loss: 1.3954 - acc: 0.5770\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 22s 128ms/step - loss: 1.3493 - acc: 0.5889\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 22s 128ms/step - loss: 1.3113 - acc: 0.5985\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 22s 128ms/step - loss: 1.2767 - acc: 0.6073\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 22s 127ms/step - loss: 1.2431 - acc: 0.6161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dANXBFru_th0"
      },
      "source": [
        "Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpRNWTy5-bh4",
        "outputId": "67247b9e-ce5d-4715-d26b-5fe658fc230f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgQfg5Jd_2Zl"
      },
      "source": [
        "new_model=tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,embedding_dim,\n",
        "                                batch_input_shape=(1,None)),\n",
        "      tf.keras.layers.GRU(rnn_units,return_sequences=True,stateful=True,\n",
        "                          recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)])\n",
        "\n",
        "new_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "new_model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWRIEQw9AGsF"
      },
      "source": [
        "def generate_text(model,start_string):\n",
        "  #Number of characters to generate\n",
        "  num_generate=1000\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "  \n",
        "  #Empty string to store our results\n",
        "  text_generated=[]\n",
        "  \n",
        "  #Low temperature results in more predictable text.\n",
        "  #Higher temperature results in more surprising text.\n",
        "  temperature=1.0\n",
        "\n",
        "  model.reset_states()\n",
        "  \n",
        "  for i in range(num_generate):\n",
        "    predictions=model(input_eval)                   #(1,6,65)  \n",
        "    #print(predictions.shape)\n",
        "    #remove the batch dimension\n",
        "    predictions=tf.squeeze(predictions,0)           #(6,65)\n",
        "    #print(predictions.shape)\n",
        "    predicitions=predictions/temperature\n",
        "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "    #print(predicted_id)\n",
        "    \n",
        "    #Pass the predicted character as the next input to the model\n",
        "    #along with the previous hidden state\n",
        "    input_eval=tf.expand_dims([predicted_id],0)       #(1,1)\n",
        "    #print(input_eval.shape)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "    \n",
        "  return (start_string+''.join(text_generated))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvMBopGYDFvB",
        "outputId": "38612bab-a6f9-40b2-e364-18a449a62219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "print(generate_text(new_model,start_string=u'ROMEO:'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Nay, or not with all rrbuse to rain.\n",
            "\n",
            "PAULINAM:\n",
            "Montague than these say, make her heart as it to leave it.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Is it, my soul's blood, when I must have in thy life;\n",
            "More, make an assarel\n",
            "Until him frown for shame,\n",
            "Which got before he will keep what I shall find my heart.\n",
            "\n",
            "YORKELO:\n",
            "You do hold for brother's blows, the princes, unhappy straight,\n",
            "On him thee.\n",
            "Have I not make a sense is.\n",
            "\n",
            "Messenger:\n",
            "I thank you, sir, be crow'st, that I enjoy by the youngest.\n",
            "\n",
            "ANGELO:\n",
            "No.\n",
            "\n",
            "CORIOLANUS:\n",
            "Ye solemn. You come to do\n",
            "As twhip the Ty-Vaiter love, and man:\n",
            "But bid he shall be will determing pate;\n",
            "Inful maid, we winge, makes for assail:\n",
            "How lougg me, do I' these you.\n",
            "\n",
            "CORIOLANUS:\n",
            "\n",
            "ANTENONIUS:\n",
            "Romeo, do for all corrue of lanful thee:\n",
            "But I'll play appear but me.\n",
            "\n",
            "TYBALT:\n",
            "A for what dost thou keep one doors:\n",
            "But, sir, sir, have us boutest and spoke dream.\n",
            "\n",
            "Nurse:\n",
            "Amen, so wandrall is he, for use you.\n",
            "Nay, is he vow, my woman, but brothers for such\n",
            "Thousand fellow 'stain'd:' quoth Warwi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E10fcyAAGDwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}